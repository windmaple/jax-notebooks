{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a direct translation of [Text generation with a miniature GPT](https://keras.io/examples/generative/text_generation_with_miniature_gpt/) from Keras to JAX/Flax."
      ],
      "metadata": {
        "id": "rvP1eNN_pExM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install JAX and Flax"
      ],
      "metadata": {
        "id": "hTmz5Cbco7n_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"jax[cuda12]\" flax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zMsOIc7ouCO",
        "outputId": "4009974b-e0d6-4920-bfef-7ba1a3627cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (0.8.4)\n",
            "Collecting flax\n",
            "  Downloading flax-0.8.5-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: jax[cuda12] in /usr/local/lib/python3.10/dist-packages (0.4.26)\n",
            "Collecting jax[cuda12]\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax[cuda12])\n",
            "  Downloading jaxlib-0.4.31-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]) (1.13.1)\n",
            "Collecting jax-cuda12-plugin<=0.4.31,>=0.4.31 (from jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12])\n",
            "  Downloading jax_cuda12_plugin-0.4.31-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax) (1.0.8)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax) (0.2.2)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax) (0.5.23)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.64)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax) (13.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax) (6.0.2)\n",
            "Collecting jax-cuda12-pjrt==0.4.31 (from jax-cuda12-plugin<=0.4.31,>=0.4.31->jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12])\n",
            "  Downloading jax_cuda12_pjrt-0.4.31-py3-none-manylinux2014_x86_64.whl.metadata (349 bytes)\n",
            "Collecting nvidia-cublas-cu12>=12.1.3.1 (from jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12])\n",
            "  Downloading nvidia_cublas_cu12-12.6.0.22-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12>=12.1.105 (from jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.37-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvcc-cu12>=12.1.105 (from jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12])\n",
            "  Downloading nvidia_cuda_nvcc_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12>=12.1.105 (from jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.37-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cudnn-cu12<10.0,>=9.1 (from jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12])\n",
            "  Downloading nvidia_cudnn_cu12-9.3.0.75-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu12>=11.0.2.54 (from jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12])\n",
            "  Downloading nvidia_cufft_cu12-11.2.6.28-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12>=11.4.5.107 (from jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.4.38-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12>=12.1.0.106 (from jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12])\n",
            "  Downloading nvidia_cusparse_cu12-12.5.2.23-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12>=2.18.1 (from jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12])\n",
            "  Downloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12>=12.1.105 (from jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12])\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (0.1.86)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.7.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (3.20.3)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->flax) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (2024.6.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.4.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.20.0)\n",
            "Downloading jaxlib-0.4.31-cp310-cp310-manylinux2014_x86_64.whl (88.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.1/88.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flax-0.8.5-py3-none-any.whl (731 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.3/731.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.4.31-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_cuda12_plugin-0.4.31-cp310-cp310-manylinux2014_x86_64.whl (14.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_cuda12_pjrt-0.4.31-py3-none-manylinux2014_x86_64.whl (84.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.0.22-py3-none-manylinux2014_x86_64.whl (368.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.0/368.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.37-py3-none-manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.37-py3-none-manylinux2014_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.3.0.75-py3-none-manylinux2014_x86_64.whl (577.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.2/577.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.6.28-py3-none-manylinux2014_x86_64.whl (192.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.4.38-py3-none-manylinux2014_x86_64.whl (130.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.2.23-py3-none-manylinux2014_x86_64.whl (217.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.5/217.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl (190.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: jax-cuda12-pjrt, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jax-cuda12-plugin, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jaxlib, nvidia-cusolver-cu12, jax, flax\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.26+cuda12.cudnn89\n",
            "    Uninstalling jaxlib-0.4.26+cuda12.cudnn89:\n",
            "      Successfully uninstalled jaxlib-0.4.26+cuda12.cudnn89\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.26\n",
            "    Uninstalling jax-0.4.26:\n",
            "      Successfully uninstalled jax-0.4.26\n",
            "  Attempting uninstall: flax\n",
            "    Found existing installation: flax 0.8.4\n",
            "    Uninstalling flax-0.8.4:\n",
            "      Successfully uninstalled flax-0.8.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.6.0.22 which is incompatible.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.6.37 which is incompatible.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.6.37 which is incompatible.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.6.28 which is incompatible.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.4.38 which is incompatible.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.2.23 which is incompatible.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.22.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flax-0.8.5 jax-0.4.31 jax-cuda12-pjrt-0.4.31 jax-cuda12-plugin-0.4.31 jaxlib-0.4.31 nvidia-cublas-cu12-12.6.0.22 nvidia-cuda-cupti-cu12-12.6.37 nvidia-cuda-nvcc-cu12-12.6.20 nvidia-cuda-runtime-cu12-12.6.37 nvidia-cudnn-cu12-9.3.0.75 nvidia-cufft-cu12-11.2.6.28 nvidia-cusolver-cu12-11.6.4.38 nvidia-cusparse-cu12-12.5.2.23 nvidia-nccl-cu12-2.22.3 nvidia-nvjitlink-cu12-12.6.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the training data."
      ],
      "metadata": {
        "id": "OHzJ_bokoovZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olwq3MrpojcJ",
        "outputId": "4be86fdc-984f-47a3-d7fb-93227f8dad9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  13.0M      0  0:00:06  0:00:06 --:--:-- 17.4M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and train the model."
      ],
      "metadata": {
        "id": "rPyt7MV6prz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax.linen as nn\n",
        "import optax\n",
        "from typing import Any, Callable\n",
        "import os\n",
        "import string\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from flax.training import train_state\n",
        "import keras\n",
        "\n",
        "\n",
        "def causal_attention_mask(seq_len):\n",
        "    \"\"\"\n",
        "    Generates a causal attention mask for self-attention.\n",
        "    \"\"\"\n",
        "    return jnp.tril(jnp.ones((seq_len, seq_len)))\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    embed_dim: int\n",
        "    num_heads: int\n",
        "    ff_dim: int\n",
        "    rate: float = 0.1\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, inputs, training: bool = False):\n",
        "        input_shape = inputs.shape\n",
        "        batch_size, seq_len, _ = input_shape\n",
        "\n",
        "        # Create causal mask\n",
        "        mask = causal_attention_mask(seq_len)\n",
        "\n",
        "        # Apply MultiHeadAttention with causal mask\n",
        "        attention_output = nn.MultiHeadAttention(num_heads=self.num_heads)(\n",
        "            inputs_q=inputs,\n",
        "            inputs_kv=inputs,\n",
        "            mask=mask\n",
        "        )\n",
        "        attention_output = nn.Dropout(rate=self.rate)(attention_output, deterministic=not training)\n",
        "        out1 = nn.LayerNorm(epsilon=1e-6)(inputs + attention_output)\n",
        "\n",
        "        # Feed-forward network\n",
        "        ffn_output = nn.Dense(features=self.ff_dim)(out1)\n",
        "        ffn_output = nn.relu(ffn_output)\n",
        "        ffn_output = nn.Dense(features=self.embed_dim)(ffn_output)\n",
        "        ffn_output = nn.Dropout(rate=self.rate)(ffn_output, deterministic=not training)\n",
        "\n",
        "        return nn.LayerNorm(epsilon=1e-6)(out1 + ffn_output)\n",
        "\n",
        "\n",
        "class TokenAndPositionEmbedding(nn.Module):\n",
        "    maxlen: int\n",
        "    vocab_size: int\n",
        "    embed_dim: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        positions = jnp.arange(0, self.maxlen)[None, :]\n",
        "        position_embedding = nn.Embed(self.maxlen, self.embed_dim)(positions)\n",
        "        token_embedding = nn.Embed(int(self.vocab_size), self.embed_dim)(x)\n",
        "        return token_embedding + position_embedding\n",
        "\n",
        "\n",
        "class MiniGPT(nn.Module):\n",
        "    maxlen: int\n",
        "    vocab_size: int\n",
        "    embed_dim: int\n",
        "    num_heads: int\n",
        "    feed_forward_dim: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, inputs, training: bool = False):\n",
        "        embedding_layer = TokenAndPositionEmbedding(\n",
        "            self.maxlen, self.vocab_size, self.embed_dim\n",
        "        )\n",
        "        x = embedding_layer(inputs)\n",
        "        transformer_block = TransformerBlock(\n",
        "            self.embed_dim, self.num_heads, self.feed_forward_dim\n",
        "        )\n",
        "        x = transformer_block(x, training=training)\n",
        "        outputs = nn.Dense(features=self.vocab_size)(x)\n",
        "        return outputs, x\n",
        "\n",
        "\n",
        "vocab_size = 20000\n",
        "maxlen = 80\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "feed_forward_dim = 256\n",
        "batch_size = 640\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    return MiniGPT(maxlen, vocab_size, embed_dim, num_heads, feed_forward_dim)\n",
        "\n",
        "\n",
        "# Data loading and preprocessing\n",
        "filenames = []\n",
        "directories = [\n",
        "    \"./aclImdb/train/pos\",\n",
        "    \"./aclImdb/train/neg\",\n",
        "    \"./aclImdb/test/pos\",\n",
        "    \"./aclImdb/test/neg\",\n",
        "]\n",
        "for dir in directories:\n",
        "    for f in os.listdir(dir):\n",
        "        filenames.append(os.path.join(dir, f))\n",
        "\n",
        "print(f\"{len(filenames)} files\")\n",
        "\n",
        "random.shuffle(filenames)\n",
        "text_ds = tf.data.TextLineDataset(filenames)\n",
        "text_ds = text_ds.shuffle(buffer_size=256)\n",
        "text_ds = text_ds.batch(batch_size)\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercased = tf.strings.lower(input_string)\n",
        "    stripped_html = tf.strings.regex_replace(lowercased, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(stripped_html, f\"([{string.punctuation}])\", r\" \\1\")\n",
        "\n",
        "\n",
        "vectorize_layer = keras.layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size - 1,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=maxlen + 1,\n",
        ")\n",
        "vectorize_layer.adapt(text_ds)\n",
        "vocab = vectorize_layer.get_vocabulary()  # To get words back from token indices\n",
        "\n",
        "\n",
        "def prepare_lm_inputs_labels(text):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "text_ds = text_ds.map(prepare_lm_inputs_labels)\n",
        "text_ds = text_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "# JAX doesn't have a direct equivalent to Keras callbacks, so we'll implement the text generation as a separate function\n",
        "def generate_text(params, max_tokens, start_tokens, index_to_word, top_k=10):\n",
        "    model = create_model()\n",
        "\n",
        "    def sample_from(logits):\n",
        "        logits, indices = jax.lax.top_k(logits, k=top_k)\n",
        "        logits = jax.nn.softmax(logits)\n",
        "        return jax.random.choice(jax.random.PRNGKey(0), indices, p=logits)\n",
        "\n",
        "    def generate_step(start_tokens):\n",
        "        pad_len = maxlen - len(start_tokens)\n",
        "        sample_index = len(start_tokens) - 1\n",
        "        if pad_len < 0:\n",
        "            x = jnp.array(start_tokens[:maxlen])\n",
        "            sample_index = maxlen - 1\n",
        "        elif pad_len > 0:\n",
        "            x = jnp.array(start_tokens + [0] * pad_len)\n",
        "        else:\n",
        "            x = jnp.array(start_tokens)\n",
        "\n",
        "        x = x[None, :]\n",
        "        logits, _ = model.apply({\"params\": params}, x)\n",
        "        next_token = sample_from(logits[0][sample_index])\n",
        "        return next_token\n",
        "\n",
        "    generated = []\n",
        "    for _ in range(max_tokens):\n",
        "        next_token = generate_step(start_tokens + generated)\n",
        "        generated.append(int(next_token))\n",
        "    print(generated)\n",
        "    return \" \".join([index_to_word[token] for token in start_tokens + generated])\n",
        "\n",
        "\n",
        "# Training loop\n",
        "def create_train_state(rng):\n",
        "    model = create_model()\n",
        "    params = model.init(rng, jnp.ones((1, maxlen), dtype=jnp.int32))[\"params\"]\n",
        "    tx = optax.adam(learning_rate=1e-3)\n",
        "    return train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def train_step(state, batch):\n",
        "    def loss_fn(params):\n",
        "        logits, _ = state.apply_fn({\"params\": params}, batch[0])\n",
        "        loss = optax.softmax_cross_entropy_with_integer_labels(logits, batch[1]).mean()\n",
        "        return loss\n",
        "\n",
        "    grad_fn = jax.value_and_grad(loss_fn)\n",
        "    loss, grads = grad_fn(state.params)\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    return state, loss\n",
        "\n",
        "\n",
        "rng = jax.random.PRNGKey(0)\n",
        "state = create_train_state(rng)\n",
        "\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in text_ds:\n",
        "        batch = (jnp.array(batch[0].numpy()), jnp.array(batch[1].numpy()))\n",
        "        state, loss = train_step(state, batch)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss}\")\n",
        "    start_prompt = \"this movie is\"\n",
        "    start_tokens = [\n",
        "        vectorize_layer.get_vocabulary().index(word)\n",
        "        for word in start_prompt.split()\n",
        "    ]\n",
        "    generated_text = generate_text(\n",
        "        state.params, 40, start_tokens, vectorize_layer.get_vocabulary()\n",
        "    )\n",
        "    print(f\"Generated text:\\n{generated_text}\\n\")\n",
        "\n",
        "# Final text generation\n",
        "start_tokens = [\n",
        "    vectorize_layer.get_vocabulary().index(word) for word in start_prompt.split()\n",
        "]\n",
        "generated_text = generate_text(\n",
        "    state.params, 40, start_tokens, vectorize_layer.get_vocabulary()\n",
        ")\n",
        "print(f\"Final generated text:\\n{generated_text}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExIFGGGMpk3O",
        "outputId": "16cf478e-4066-4d5a-f283-66b828198c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 files\n",
            "Epoch 1, Loss: 5.563542366027832\n",
            "[28, 2, 71, 9, 28, 47, 17, 10, 3, 2, 71, 4, 12, 58, 33, 34, 7, 2, 71, 7, 2, 96, 22, 9, 28, 8, 114, 3, 3, 10, 3, 10, 16, 34, 7, 2, 122, 3, 3, 10]\n",
            "Generated text:\n",
            "this movie is not the story is not just as it . the story , i can be one of the story of the first film is not to watch . . it . it was one of the plot . . it\n",
            "\n",
            "Epoch 2, Loss: 4.921992778778076\n",
            "[2, 96, 18, 4, 21, 12, 218, 10, 15, 47, 95, 12, 156, 259, 4, 21, 10, 3, 2, 1, 27, 16, 43, 89, 4, 10, 9, 28, 2, 1, 27, 6, 10, 9, 34, 3, 10, 9, 34, 7]\n",
            "Generated text:\n",
            "this movie is the first movie , but i saw it 's just because i 'm sure , but it . the [UNK] \" was so bad , it is not the [UNK] \" and it is one . it is one of\n",
            "\n",
            "Epoch 3, Loss: 4.750950336456299\n",
            "[2, 18, 14, 52, 8, 33, 34, 7, 2, 257, 7, 2, 128, 18, 3, 2, 96, 12, 16, 28, 70, 57, 17, 5, 181, 216, 12, 245, 259, 53, 10, 9, 28, 68, 2, 96, 4, 12, 156, 5]\n",
            "Generated text:\n",
            "this movie is the movie that has to be one of the worst of the best movie . the first i was not really good as a few times i am sure if it is not even the first , i 'm a\n",
            "\n",
            "Epoch 4, Loss: 4.637650966644287\n",
            "[34, 7, 2, 257, 115, 132, 103, 11, 13, 22, 3, 2, 96, 7, 36, 12, 148, 132, 118, 4, 21, 10, 9, 2, 69, 5, 237, 3, 10, 9, 34, 7, 2, 257, 115, 132, 103, 4, 12, 32]\n",
            "Generated text:\n",
            "this movie is one of the worst films ever made in this film . the first of all i 've ever seen , but it is the only a bit . it is one of the worst films ever made , i have\n",
            "\n",
            "Epoch 5, Loss: 4.47239875793457\n",
            "[34, 7, 2, 257, 18, 12, 148, 132, 118, 3, 10, 15, 28, 166, 3, 10, 15, 28, 2, 122, 3, 10, 9, 2, 257, 3, 3, 2, 69, 34, 9, 34, 7, 2, 97, 184, 7, 2, 18, 4]\n",
            "Generated text:\n",
            "this movie is one of the worst movie i 've ever seen . it 's not funny . it 's not the plot . it is the worst . . the only one is one of the most part of the movie ,\n",
            "\n",
            "Epoch 6, Loss: 4.2808122634887695\n",
            "[2, 69, 34, 12, 32, 132, 118, 3, 10, 15, 47, 1042, 6, 5, 181, 7, 108, 14, 9, 43, 393, 14, 24, 105, 114, 13, 22, 3, 10, 15, 47, 1042, 256, 8, 114, 10, 4, 24, 127, 10]\n",
            "Generated text:\n",
            "this movie is the only one i have ever seen . it 's just plain and a few of movies that is so awful that you could watch this film . it 's just plain fun to watch it , you know it\n",
            "\n",
            "Epoch 7, Loss: 4.167908668518066\n",
            "[43, 393, 14, 10, 15, 47, 49, 5, 139, 793, 1017, 3373, 4, 6, 2, 18, 52, 65, 34, 8, 144, 10, 15, 2, 96, 34, 4, 2, 128, 7, 36, 2, 111, 29, 1, 6, 1, 1, 1, 23]\n",
            "Generated text:\n",
            "this movie is so awful that it 's just about a man named joe buck , and the movie has no one to say it 's the first one , the best of all the characters are [UNK] and [UNK] [UNK] [UNK] )\n",
            "\n",
            "Epoch 8, Loss: 4.007929801940918\n",
            "[43, 393, 4, 2, 122, 4, 10, 9, 43, 263, 8, 175, 51, 46, 4, 65, 782, 50, 109, 7, 10, 3, 2, 122, 9, 43, 357, 3, 12, 32, 121, 118, 5, 22, 4, 10, 9, 43, 357, 4]\n",
            "Generated text:\n",
            "this movie is so awful , the plot , it is so hard to find out there , no suspense or any of it . the plot is so boring . i have never seen a film , it is so boring ,\n",
            "\n",
            "Epoch 9, Loss: 3.9468114376068115\n",
            "[28, 2, 69, 18, 12, 218, 2, 1526, 25, 10, 4, 12, 74, 118, 10, 6, 74, 8, 114, 10, 19, 66, 442, 3, 10, 15, 28, 47, 49, 5, 378, 7, 216, 6, 10, 9, 47, 1042, 6, 2]\n",
            "Generated text:\n",
            "this movie is not the only movie i saw the trailer on it , i had seen it and had to watch it with my friend . it 's not just about a couple of times and it is just plain and the\n",
            "\n",
            "Epoch 10, Loss: 3.780479669570923\n",
            "[2, 128, 18, 12, 32, 132, 118, 3, 10, 15, 199, 76, 42, 5, 18, 6, 10, 9, 166, 6, 12, 156, 143, 5, 207, 336, 7, 1, 4, 21, 10, 9, 47, 43, 166, 14, 10, 9, 3, 10]\n",
            "Generated text:\n",
            "this movie is the best movie i have ever seen . it 's got me from a movie and it is funny and i 'm still a big fan of [UNK] , but it is just so funny that it is . it\n",
            "\n",
            "Epoch 11, Loss: 3.6964612007141113\n",
            "[43, 393, 3, 12, 112, 2, 163, 77, 70, 90, 6, 12, 201, 2, 163, 77, 61, 79, 3, 12, 32, 65, 327, 98, 12, 58, 85, 3, 3, 2, 71, 16, 61, 230, 4, 6, 12, 32, 5, 131]\n",
            "Generated text:\n",
            "this movie is so awful . i think the actors were really great and i thought the actors were very well . i have no idea how i can get . . the story was very interesting , and i have a little\n",
            "\n",
            "Epoch 12, Loss: 3.6117546558380127\n",
            "[2, 69, 18, 12, 148, 118, 3, 10, 15, 47, 43, 236, 6, 257, 3, 10, 9, 43, 89, 3, 12, 388, 10, 15, 47, 49, 10, 4, 12, 99, 26, 70, 44, 13, 3, 10, 15, 47, 28, 3]\n",
            "Generated text:\n",
            "this movie is the only movie i 've seen . it 's just so far and worst . it is so bad . i mean it 's just about it , i don 't really like this . it 's just not .\n",
            "\n",
            "Epoch 13, Loss: 3.5954830646514893\n",
            "[2, 69, 18, 12, 148, 118, 3, 10, 15, 47, 43, 236, 6, 2, 128, 3, 12, 148, 118, 13, 18, 6, 10, 15, 166, 4, 28, 5, 57, 158, 49, 10, 9, 3, 12, 388, 10, 15, 28, 14]\n",
            "Generated text:\n",
            "this movie is the only movie i 've seen . it 's just so far and the best . i 've seen this movie and it 's funny , not a good thing about it is . i mean it 's not that\n",
            "\n",
            "Epoch 14, Loss: 3.5289306640625\n",
            "[2, 69, 106, 154, 10, 9, 14, 10, 15, 84, 1, 27, 6, 12, 148, 84, 160, 2, 96, 117, 702, 4, 21, 13, 34, 52, 84, 1, 20, 5, 181, 1845, 6, 143, 1750, 2, 616, 7, 2, 96]\n",
            "Generated text:\n",
            "this movie is the only way through it is that it 's been [UNK] \" and i 've been watching the first two episodes , but this one has been [UNK] for a few months and still holds the interest of the first\n",
            "\n",
            "Epoch 15, Loss: 3.45615291595459\n",
            "[2, 69, 106, 8, 2, 122, 3, 10, 15, 47, 49, 2, 124, 9, 345, 6, 2, 238, 3, 10, 9, 61, 263, 8, 266, 2, 69, 293, 149, 13, 18, 16, 14, 2, 288, 293, 20, 2, 22, 16]\n",
            "Generated text:\n",
            "this movie is the only way to the plot . it 's just about the acting is poor and the script . it is very hard to believe the only reason why this movie was that the main reason for the film was\n",
            "\n",
            "Epoch 16, Loss: 3.3382132053375244\n",
            "[2, 69, 106, 10, 15, 2, 71, 7, 5, 131, 432, 41, 16, 271, 8, 851, 51, 55, 30, 105, 91, 54, 12, 16, 11, 13, 18, 54, 12, 64, 44, 8, 127, 98, 13, 18, 54, 12, 156, 826]\n",
            "Generated text:\n",
            "this movie is the only way it 's the story of a little boy who was trying to figure out what he could do ? i was in this movie ? i would like to know how this movie ? i 'm sorry\n",
            "\n",
            "Epoch 17, Loss: 3.2595646381378174\n",
            "[2, 69, 18, 12, 148, 118, 3, 12, 58, 69, 144, 2, 18, 12, 32, 118, 11, 5, 206, 67, 3, 10, 15, 47, 43, 81, 59, 12, 105, 73, 59, 7, 5, 22, 82, 10, 16, 11, 165, 3]\n",
            "Generated text:\n",
            "this movie is the only movie i 've seen . i can only say the movie i have seen in a long time . it 's just so much more i could see more of a film than it was in years .\n",
            "\n",
            "Epoch 18, Loss: 3.231837034225464\n",
            "[2, 69, 18, 12, 148, 118, 246, 3, 10, 9, 34, 7, 66, 36, 67, 2545, 3, 12, 58, 26, 399, 98, 116, 108, 151, 4, 13, 9, 4, 2, 122, 4, 6, 12, 58, 144, 2, 124, 4, 2]\n",
            "Generated text:\n",
            "this movie is the only movie i 've seen since . it is one of my all time favorites . i can 't remember how many movies such , this is , the plot , and i can say the acting , the\n",
            "\n",
            "Epoch 19, Loss: 3.1974568367004395\n",
            "[43, 392, 4, 6, 47, 1042, 89, 3, 10, 15, 5, 375, 1281, 507, 14, 52, 56, 7, 2, 97, 652, 4, 21, 13, 18, 16, 2, 97, 375, 12, 32, 132, 118, 3, 12, 16, 1020, 10, 8, 33]\n",
            "Generated text:\n",
            "this movie is so terrible , and just plain bad . it 's a stupid slasher flick that has some of the most ridiculous , but this movie was the most stupid i have ever seen . i was expecting it to be\n",
            "\n",
            "Epoch 20, Loss: 3.165971279144287\n",
            "[28, 47, 392, 3, 2, 122, 9, 43, 723, 3, 10, 15, 28, 68, 285, 324, 4, 12, 64, 32, 84, 5, 237, 7, 2559, 20, 13, 18, 3, 2, 71, 9, 43, 596, 3, 12, 112, 2, 71, 9]\n",
            "Generated text:\n",
            "this movie is not just terrible . the plot is so predictable . it 's not even worth seeing , i would have been a bit of praise for this movie . the story is so simple . i think the story is\n",
            "\n",
            "Epoch 21, Loss: 3.0820977687835693\n",
            "[43, 81, 5, 256, 4, 12, 201, 10, 16, 90, 4, 21, 10, 16, 61, 79, 3, 2, 124, 16, 57, 6, 2, 122, 16, 193, 89, 3, 10, 15, 70, 57, 4, 12, 164, 26, 70, 32, 5, 177]\n",
            "Generated text:\n",
            "this movie is so much a fun , i thought it was great , but it was very well . the acting was good and the plot was pretty bad . it 's really good , i didn 't really have a lot\n",
            "\n",
            "Epoch 22, Loss: 2.990772247314453\n",
            "[2, 257, 12, 148, 132, 118, 3, 12, 156, 28, 628, 10, 15, 28, 166, 4, 10, 15, 47, 43, 89, 4, 6, 2, 122, 4, 2, 122, 4, 2, 111, 29, 61, 830, 4, 6, 24, 127, 10, 15]\n",
            "Generated text:\n",
            "this movie is the worst i 've ever seen . i 'm not saying it 's not funny , it 's just so bad , and the plot , the plot , the characters are very believable , and you know it 's\n",
            "\n",
            "Epoch 23, Loss: 2.9731454849243164\n",
            "[43, 393, 12, 105, 121, 33, 34, 7, 2, 128, 1, 27, 18, 12, 32, 132, 118, 3, 10, 9, 34, 7, 66, 526, 108, 132, 3, 10, 15, 28, 43, 89, 4, 12, 99, 26, 112, 12, 64, 44]\n",
            "Generated text:\n",
            "this movie is so awful i could never be one of the best [UNK] \" movie i have ever seen . it is one of my favorite movies ever . it 's not so bad , i don 't think i would like\n",
            "\n",
            "Epoch 24, Loss: 3.003370523452759\n",
            "[2, 128, 7, 2, 128, 184, 7, 2, 1174, 15, 14, 24, 32, 8, 73, 3, 12, 58, 26, 350, 21, 13, 9, 2, 257, 18, 12, 32, 132, 118, 3, 10, 9, 2, 124, 9, 500, 3, 12, 148]\n",
            "Generated text:\n",
            "this movie is the best of the best part of the 90 's that you have to see . i can 't help but this is the worst movie i have ever seen . it is the acting is horrible . i 've\n",
            "\n",
            "Epoch 25, Loss: 2.8689959049224854\n",
            "[28, 47, 43, 89, 3, 2, 122, 9, 5, 1478, 9381, 139, 675, 257, 124, 12, 148, 132, 118, 4, 12, 32, 132, 118, 4, 43, 12, 32, 65, 327, 149, 13, 18, 16, 103, 20, 5, 22, 54, 2]\n",
            "Generated text:\n",
            "this movie is not just so bad . the plot is a cliché ridden man whose worst acting i 've ever seen , i have ever seen , so i have no idea why this movie was made for a film ? the\n",
            "\n",
            "[28, 47, 43, 89, 3, 2, 122, 9, 5, 1478, 9381, 139, 675, 257, 124, 12, 148, 132, 118, 4, 12, 32, 132, 118, 4, 43, 12, 32, 65, 327, 149, 13, 18, 16, 103, 20, 5, 22, 54, 2]\n",
            "Final generated text:\n",
            "this movie is not just so bad . the plot is a cliché ridden man whose worst acting i 've ever seen , i have ever seen , so i have no idea why this movie was made for a film ? the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z0p-IHurrB9i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}